{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip3 install psycopg2\n",
        "!pip3 install --upgrade setuptools pip\n",
        "!pip install nest-asyncio\n",
        "!pip3 install pytelegrambotapi\n",
        "!pip install aiogram"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JPHvCAy5Mh1w",
        "outputId": "6ea99730-f76b-4b6a-df87-731bbf385fbb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: psycopg2 in /usr/local/lib/python3.10/dist-packages (2.9.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (71.0.4)\n",
            "Collecting setuptools\n",
            "  Using cached setuptools-75.1.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB)\n",
            "Using cached setuptools-75.1.0-py3-none-any.whl (1.2 MB)\n",
            "Using cached pip-24.2-py3-none-any.whl (1.8 MB)\n",
            "Installing collected packages: setuptools, pip\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 71.0.4\n",
            "    Uninstalling setuptools-71.0.4:\n",
            "      Successfully uninstalled setuptools-71.0.4\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pip-24.2 setuptools-75.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "pkg_resources",
                  "setuptools"
                ]
              },
              "id": "f1c18600dc6640669048e33e28caf330"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Collecting pytelegrambotapi\n",
            "  Downloading pytelegrambotapi-4.22.1-py3-none-any.whl.metadata (48 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pytelegrambotapi) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pytelegrambotapi) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pytelegrambotapi) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pytelegrambotapi) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pytelegrambotapi) (2024.8.30)\n",
            "Downloading pytelegrambotapi-4.22.1-py3-none-any.whl (261 kB)\n",
            "Installing collected packages: pytelegrambotapi\n",
            "Successfully installed pytelegrambotapi-4.22.1\n",
            "Collecting aiogram\n",
            "  Downloading aiogram-3.13.1-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting aiofiles<24.2,>=23.2.1 (from aiogram)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: aiohttp<3.11,>=3.9.0 in /usr/local/lib/python3.10/dist-packages (from aiogram) (3.10.5)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from aiogram) (2024.8.30)\n",
            "Collecting magic-filter<1.1,>=1.0.12 (from aiogram)\n",
            "  Downloading magic_filter-1.0.12-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pydantic<2.10,>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from aiogram) (2.9.1)\n",
            "Requirement already satisfied: typing-extensions<=5.0,>=4.7.0 in /usr/local/lib/python3.10/dist-packages (from aiogram) (4.12.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<3.11,>=3.9.0->aiogram) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<3.11,>=3.9.0->aiogram) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<3.11,>=3.9.0->aiogram) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<3.11,>=3.9.0->aiogram) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<3.11,>=3.9.0->aiogram) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<3.11,>=3.9.0->aiogram) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<3.11,>=3.9.0->aiogram) (4.0.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.10,>=2.4.1->aiogram) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.10,>=2.4.1->aiogram) (2.23.3)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp<3.11,>=3.9.0->aiogram) (3.10)\n",
            "Downloading aiogram-3.13.1-py3-none-any.whl (588 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.7/588.7 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading magic_filter-1.0.12-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: magic-filter, aiofiles, aiogram\n",
            "Successfully installed aiofiles-24.1.0 aiogram-3.13.1 magic-filter-1.0.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3bZsPe1jAzdu"
      },
      "outputs": [],
      "source": [
        "# Импорт библиотек\n",
        "import re\n",
        "\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import telebot\n",
        "\n",
        "import asyncio\n",
        "from aiogram import Bot, types\n",
        "from aiogram import  Dispatcher\n",
        "from aiogram.filters import CommandStart, Command\n",
        "from aiogram.fsm.context import FSMContext\n",
        "from aiogram.fsm.storage.memory import MemoryStorage\n",
        "from aiogram.fsm.state import StatesGroup, State\n",
        "from aiogram.types import Message\n",
        "from aiogram import F\n",
        "from aiogram.types.input_file import FSInputFile\n",
        "import nest_asyncio\n",
        "from aiogram.types import InlineKeyboardMarkup, InlineKeyboardButton"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQSz3GPJAzkM"
      },
      "outputs": [],
      "source": [
        "bot = Bot(token='******')\n",
        "\n",
        "dp = Dispatcher(storage = MemoryStorage())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ptg2gT6T6i14"
      },
      "outputs": [],
      "source": [
        "class style_image(StatesGroup):\n",
        "    choosing_style = State()\n",
        "    recieve_content = State()\n",
        "    processing = State()\n",
        "    style = State()\n",
        "    anystyle = State()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ds0JZqJsN64S"
      },
      "outputs": [],
      "source": [
        "@dp.message(Command(\"start\"))\n",
        "async def cmd_hello(message: Message, state: FSMContext):\n",
        "    l = []\n",
        "    l =[[InlineKeyboardButton(text ='Перенос стиля c одного изображения на другое',callback_data = 'style')],\n",
        "        [InlineKeyboardButton(text='Превращение лошади в зебру', callback_data = 'horse2zebra')],\n",
        "        [InlineKeyboardButton(text='Превращение зимы в лето', callback_data = 'winter2summer_yosemite')],\n",
        "        [InlineKeyboardButton(text='Превращение яблок в апельсины', callback_data = 'apple')],\n",
        "        [InlineKeyboardButton(text='Обработка изображения в стиле Моне', callback_data = 'mone')],\n",
        "        [InlineKeyboardButton(text='Обработка изображения в стиле Сезанна', callback_data = 'sezan')],\n",
        "        [InlineKeyboardButton(text='Обработка изображения в стиле Ван Гога', callback_data = 'gog')]]\n",
        "    markup =  InlineKeyboardMarkup(inline_keyboard=l)\n",
        "    await state.set_state(style_image.choosing_style)\n",
        "    await message.answer(\n",
        "        \"Добро пожаловать! Я чат-бот по обработке изображений. Выберите опцию:\", reply_markup = markup\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGsObpwrl_V4"
      },
      "outputs": [],
      "source": [
        "@dp.message(Command(\"main_menu\"))\n",
        "async def cmd_hello(message: Message, state: FSMContext):\n",
        "  l = []\n",
        "  l =[[InlineKeyboardButton(text ='Перенос стиля c одного изображения на другое',callback_data = 'style')],\n",
        "      [InlineKeyboardButton(text='Превращение лошади в зебру', callback_data = 'horse2zebra')],\n",
        "      [InlineKeyboardButton(text='Превращение зимы в лето', callback_data = 'winter2summer_yosemite')],\n",
        "      [InlineKeyboardButton(text='Обработка изображения в стиле Моне', callback_data = 'mone')],\n",
        "      [InlineKeyboardButton(text='Обработка изображения в стиле Сезанна', callback_data = 'sezan')],\n",
        "      [InlineKeyboardButton(text='Обработка изображения в стиле Ван Гога', callback_data = 'gog')]]\n",
        "  await state.set_state(style_image.choosing_style)\n",
        "  markup =  InlineKeyboardMarkup(inline_keyboard=l)\n",
        "  await message.answer(\n",
        "        \"Я чат-бот по обработке изображений. Выберите опцию:\", reply_markup = markup\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1j2c6fidELF"
      },
      "outputs": [],
      "source": [
        "@dp.callback_query(F.data == 'style', style_image.choosing_style)\n",
        "async def answer (callback: types.CallbackQuery , state: FSMContext):\n",
        "  await state.set_state(style_image.style)\n",
        "  await state.update_data(choosing_style='style')\n",
        "  await callback.message.edit_text(\"Загрузи любое изображение для обработки, потом изображение, с которого будет перенесен стиль\")\n",
        "\n",
        "\n",
        "@dp.callback_query(F.data == 'horse2zebra', style_image.choosing_style)\n",
        "async def answer (callback: types.CallbackQuery , state: FSMContext):\n",
        "  await state.set_state(style_image.recieve_content)\n",
        "  await state.update_data(choosing_style='horse2zebra')\n",
        "  await callback.message.edit_text(\"Загрузи изображение лошади для превращения её в зебру\")\n",
        "\n",
        "\n",
        "@dp.callback_query(F.data == 'winter2summer_yosemite',style_image.choosing_style)\n",
        "async def answer (callback: types.CallbackQuery, state: FSMContext):\n",
        "  await state.set_state(style_image.recieve_content)\n",
        "  data = await state.update_data(choosing_style='winter2summer_yosemite')\n",
        "  await callback.message.edit_text(\"Загрузи любое изображение зимы для превращения её в лето\")\n",
        "\n",
        "@dp.callback_query(F.data == 'mone', style_image.choosing_style)\n",
        "async def answer (callback: types.CallbackQuery, state: FSMContext):\n",
        "  await state.set_state(style_image.recieve_content)\n",
        "  data = await state.update_data(choosing_style=F.data)\n",
        "  await callback.message.edit_text(\"Загрузи любое изображение для стилизации под Моне\")\n",
        "\n",
        "@dp.callback_query(F.data == 'sezan', style_image.choosing_style)\n",
        "async def answer (callback: types.CallbackQuery, state: FSMContext):\n",
        "  await state.set_state(style_image.recieve_content)\n",
        "  data = await state.update_data(choosing_style='sezan')\n",
        "  await callback.message.edit_text(\"Загрузи любое изображение для стилизации под Сезанна\")\n",
        "\n",
        "@dp.callback_query(F.data == 'gog', style_image.choosing_style)\n",
        "async def answer (callback: types.CallbackQuery, state: FSMContext):\n",
        "  await state.set_state(style_image.recieve_content)\n",
        "  data = await state.update_data(choosing_style='gog')\n",
        "  await callback.message.edit_text(\"Загрузи любое изображение для стилизации под Ван Гога\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FtsqRfQhWkOX"
      },
      "outputs": [],
      "source": [
        "@dp.message(F.photo, style_image.style)\n",
        "async def photo_processing(message, state: FSMContext):\n",
        "  await message.bot.download(file=message.photo[-1].file_id, destination='/opt/keksbot/content.png')\n",
        "  await state.set_state(style_image.recieve_content)\n",
        "  await message.answer('Получено изображение для обработки. Загрузи изображение, с которого будет перенес стиль')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eIHP0-4GfdJp"
      },
      "outputs": [],
      "source": [
        "@dp.message(F.photo, style_image.recieve_content)\n",
        "async def photo_processing(message):\n",
        "  await message.bot.download(file=message.photo[-1].file_id, destination='/opt/keksbot/Untitled/style.png')\n",
        "  await message.answer('Получено изображение для редактирования. Для обработки нажми команду /processing')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZSF8_OkvPSN"
      },
      "outputs": [],
      "source": [
        "@dp.message(F.photo)\n",
        "async def photo_processing(message):\n",
        "  await message.answer('Сначала выбери стиль обработки изображения /main_menu')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6XAbIv7_jFKf"
      },
      "outputs": [],
      "source": [
        "@dp.message(Command ('processing'))\n",
        "async def processing(message, state: FSMContext):\n",
        "  data = await state.get_data()\n",
        "  try:\n",
        "    await message.answer(text='Изображение обрабатывается...')\n",
        "    if data.get('choosing_style') == 'style':\n",
        "      path = '/opt/keksbot/content_fake.png'\n",
        "      output = run_style_transfer(cnn, cnn_normalization_mean, cnn_normalization_std,image_loader('/content/sample_data/content'), image_loader('/content/sample_data/Untitled/style'), image_loader('/content/sample_data/content').clone())\n",
        "\n",
        "    elif data.get('choosing_style') == 'horse2zebra':\n",
        "      path = '/opt/keksbot/result/horse2zebra_pretrained/test_latest/images/style_fake.png'\n",
        "      !python test.py --dataroot /opt/keksbot/Untitled --name horse2zebra_pretrained --model test --no_dropout --results_dir opt/keksbot/result\n",
        "\n",
        "    elif data.get('choosing_style') == 'winter2summer_yosemite':\n",
        "      path = '/opt/keksbot/result/winter2summer_yosemite_pretrained/test_latest/images/style_fake.png'\n",
        "      !python test.py --dataroot /opt/keksbot/Untitled --name winter2summer_yosemite_pretrained --model test --no_dropout --results_dir opt/keksbot/result\n",
        "\n",
        "    elif data.get('choosing_style') == 'mone':\n",
        "      path = '/opt/keksbot/result/style_monet_pretrained/test_latest/images/style_fake.png'\n",
        "      !python test.py --dataroot /opt/keksbot/Untitled --name style_monet_pretrained --model test --no_dropout --results_dir opt/keksbot/result\n",
        "\n",
        "    elif data.get('choosing_style') == 'sezan':\n",
        "      path = '/opt/keksbot/result/style_cezanne_pretrained/test_latest/images/style_fake.png'\n",
        "      !python test.py --dataroot /opt/keksbot/Untitled --name style_cezanne_pretrained --model test --no_dropout --results_dir opt/keksbot/result\n",
        "\n",
        "    elif data.get('choosing_style') == 'gog':\n",
        "      path = '/opt/keksbot/result/style_vangogh_pretrained/test_latest/images/style_fake.png'\n",
        "      !python test.py --dataroot /opt/keksbot/Untitled --name style_vangogh_pretrained --model test --no_dropout --results_dir opt/keksbot/result\n",
        "\n",
        "    img =  FSInputFile(path)\n",
        "    await message.answer_photo(photo=img, caption='Готово')\n",
        "\n",
        "  except:\n",
        "    await message.answer(text='Ошибка')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THIeAUi2e_sp",
        "outputId": "09b0065e-013b-445e-9c08-913a114e89a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: /content/sample_data/Untitled \t[default: None]\n",
            "             dataset_mode: single                        \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: latest                        \n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: test                          \n",
            "             model_suffix:                               \n",
            "               n_layers_D: 3                             \n",
            "                     name: horse2zebra_pretrained        \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_9blocks                \n",
            "                      ngf: 64                            \n",
            "               no_dropout: True                          \t[default: False]\n",
            "                  no_flip: False                         \n",
            "                     norm: instance                      \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: resize_and_crop               \n",
            "              results_dir: /content/sample_data/result   \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                use_wandb: False                         \n",
            "                  verbose: False                         \n",
            "       wandb_project_name: CycleGAN-and-pix2pix          \n",
            "----------------- End -------------------\n",
            "dataset [SingleDataset] was created\n",
            "initialize network with normal\n",
            "model [TestModel] was created\n",
            "loading the model from ./checkpoints/horse2zebra_pretrained/latest_net_G.pth\n",
            "/content/pytorch-CycleGAN-and-pix2pix/models/base_model.py:192: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(load_path, map_location=str(self.device))\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 11.378 M\n",
            "-----------------------------------------------\n",
            "creating web directory /content/sample_data/result/horse2zebra_pretrained/test_latest\n",
            "processing (0000)-th image... ['/content/sample_data/Untitled/style.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: /content/sample_data/Untitled \t[default: None]\n",
            "             dataset_mode: single                        \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: latest                        \n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: test                          \n",
            "             model_suffix:                               \n",
            "               n_layers_D: 3                             \n",
            "                     name: winter2summer_yosemite_pretrained\t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_9blocks                \n",
            "                      ngf: 64                            \n",
            "               no_dropout: True                          \t[default: False]\n",
            "                  no_flip: False                         \n",
            "                     norm: instance                      \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: resize_and_crop               \n",
            "              results_dir: /content/sample_data/result   \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                use_wandb: False                         \n",
            "                  verbose: False                         \n",
            "       wandb_project_name: CycleGAN-and-pix2pix          \n",
            "----------------- End -------------------\n",
            "dataset [SingleDataset] was created\n",
            "initialize network with normal\n",
            "model [TestModel] was created\n",
            "loading the model from ./checkpoints/winter2summer_yosemite_pretrained/latest_net_G.pth\n",
            "/content/pytorch-CycleGAN-and-pix2pix/models/base_model.py:192: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(load_path, map_location=str(self.device))\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 11.378 M\n",
            "-----------------------------------------------\n",
            "creating web directory /content/sample_data/result/winter2summer_yosemite_pretrained/test_latest\n",
            "processing (0000)-th image... ['/content/sample_data/Untitled/style.png']\n",
            "----------------- Options ---------------\n",
            "             aspect_ratio: 1.0                           \n",
            "               batch_size: 1                             \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "                crop_size: 256                           \n",
            "                 dataroot: /content/sample_data/Untitled \t[default: None]\n",
            "             dataset_mode: single                        \n",
            "                direction: AtoB                          \n",
            "          display_winsize: 256                           \n",
            "                    epoch: latest                        \n",
            "                     eval: False                         \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: False                         \t[default: None]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 256                           \n",
            "         max_dataset_size: inf                           \n",
            "                    model: test                          \n",
            "             model_suffix:                               \n",
            "               n_layers_D: 3                             \n",
            "                     name: style_vangogh_pretrained      \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_9blocks                \n",
            "                      ngf: 64                            \n",
            "               no_dropout: True                          \t[default: False]\n",
            "                  no_flip: False                         \n",
            "                     norm: instance                      \n",
            "                 num_test: 50                            \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: test                          \n",
            "               preprocess: resize_and_crop               \n",
            "              results_dir: /content/sample_data/result   \t[default: ./results/]\n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "                use_wandb: False                         \n",
            "                  verbose: False                         \n",
            "       wandb_project_name: CycleGAN-and-pix2pix          \n",
            "----------------- End -------------------\n",
            "dataset [SingleDataset] was created\n",
            "initialize network with normal\n",
            "model [TestModel] was created\n",
            "loading the model from ./checkpoints/style_vangogh_pretrained/latest_net_G.pth\n",
            "/content/pytorch-CycleGAN-and-pix2pix/models/base_model.py:192: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(load_path, map_location=str(self.device))\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 11.378 M\n",
            "-----------------------------------------------\n",
            "creating web directory /content/sample_data/result/style_vangogh_pretrained/test_latest\n",
            "processing (0000)-th image... ['/content/sample_data/Untitled/style.png']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:aiogram.dispatcher:Received SIGINT signal\n"
          ]
        }
      ],
      "source": [
        "async def main():\n",
        "    await bot.delete_webhook(drop_pending_updates=True)\n",
        "    await dp.start_polling(bot)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}